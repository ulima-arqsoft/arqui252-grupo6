> [0. Acerca del Grupo](../../0.md) ‚Ä∫ [0.8. Temas Individuales (Parte 2)](../0.8.md) ‚Ä∫ [0.8.1. Integrante 1](0.8.1.md)

# 0.8.1. Integrante 1

# MLOps: Machine Learning Operations

**Autor:** Cesar Montoya Rodriguez - 20223759  
**Categor√≠a:** IA / Machine Learning  
**Tema:** MLOps (Machine Learning Operations)  
**Herramienta de Ejemplo:** MLflow


---

## Tabla de Contenidos

1. [Desarrollo Conceptual](#1-desarrollo-conceptual)
   - 1.1 [¬øQu√© es MLOps?](#11-qu√©-es-mlops)
   - 1.2 [Ciclo de Vida de MLOps](#12-ciclo-de-vida-de-mlops)
   - 1.3 [Principios Fundamentales de MLOps](#13-principios-fundamentales-de-mlops)
   - 1.4 [Desaf√≠os que Aborda MLOps](#14-desaf√≠os-que-aborda-mlops)
   - 1.5 [MLOps vs DevOps](#15-mlops-vs-devops)
2. [Consideraciones T√©cnicas](#2-consideraciones-t√©cnicas)
   - 2.1 [Introducci√≥n a MLflow](#21-introducci√≥n-a-mlflow)
   - 2.2 [Componentes de MLflow](#22-componentes-de-mlflow)
   - 2.3 [Instalaci√≥n y Configuraci√≥n](#23-instalaci√≥n-y-configuraci√≥n)
   - 2.4 [Integraci√≥n con Frameworks de ML](#24-integraci√≥n-con-frameworks-de-ml)
   - 2.5 [Estrategias de Despliegue](#25-estrategias-de-despliegue)
3. [Demostraci√≥n Pr√°ctica](#3-demostraci√≥n-pr√°ctica)
   - 3.1 [Escenario de Aplicaci√≥n](#31-escenario-de-aplicaci√≥n)
   - 3.2 [Arquitectura de la Demo](#32-arquitectura-de-la-demo)
   - 3.3 [Implementaci√≥n](#33-implementaci√≥n)
   - 3.4 [Resultados y An√°lisis](#34-resultados-y-an√°lisis)
4. [Conclusiones](#4-conclusiones)
5. [Referencias](#5-referencias)

---

## 1. Desarrollo Conceptual

### 1.1 ¬øQu√© es MLOps?

**MLOps** (Machine Learning Operations) es una pr√°ctica de ingenier√≠a que combina Machine Learning (ML), DevOps y Data Engineering para estandarizar y optimizar el ciclo de vida completo de los modelos de aprendizaje autom√°tico en entornos de producci√≥n.

MLOps surge como respuesta a los desaf√≠os √∫nicos que presenta el desarrollo y despliegue de sistemas de ML, donde no solo se gestiona c√≥digo, sino tambi√©n datos, modelos, experimentos y su rendimiento continuo en producci√≥n.

#### Objetivos Principales de MLOps:

1. **Automatizaci√≥n**: Reducir la intervenci√≥n manual en el pipeline de ML, desde el entrenamiento hasta el despliegue
2. **Reproducibilidad**: Garantizar que los experimentos y modelos puedan recrearse de manera consistente
3. **Escalabilidad**: Permitir que los sistemas de ML crezcan eficientemente con el volumen de datos y demanda
4. **Monitoreo Continuo**: Supervisar el rendimiento de los modelos en producci√≥n y detectar degradaci√≥n
5. **Colaboraci√≥n**: Facilitar el trabajo conjunto entre cient√≠ficos de datos, ingenieros de ML y equipos de operaciones
6. **Gobernanza**: Asegurar el cumplimiento de regulaciones y mantener la trazabilidad de modelos

### 1.2 Ciclo de Vida de MLOps

El ciclo de vida de MLOps se compone de tres fases principales que se ejecutan de manera iterativa:

![Ciclo de Vida de MLOps](./images/ciclo_de_vida.png)

#### 1.2.1 Fase Experimental (Desarrollo)

Esta fase se centra en la concepci√≥n y prototipado de la soluci√≥n de ML:

**a) Definici√≥n del Problema**
- Identificar objetivos de negocio y m√©tricas de √©xito
- Determinar si ML es la soluci√≥n apropiada
- Definir el alcance y las restricciones del proyecto

**b) Recolecci√≥n y Preparaci√≥n de Datos**
- Identificar fuentes de datos relevantes
- Evaluar calidad y disponibilidad de datos
- Realizar limpieza y transformaci√≥n de datos
- Ingenier√≠a de caracter√≠sticas (feature engineering)
- Implementar versionado de datos
- Establecer pipelines de validaci√≥n de datos

**c) Desarrollo y Selecci√≥n de Modelos**
- Experimentar con diferentes algoritmos de ML
- Realizar ajuste de hiperpar√°metros
- Evaluar rendimiento con m√©tricas apropiadas
- Comparar m√∫ltiples modelos
- Documentar experimentos y resultados

#### 1.2.2 Fase de Producci√≥n (Despliegue)

Una vez desarrollado un modelo satisfactorio, esta fase lo hace operacional:

**a) Validaci√≥n del Modelo**
- Validaci√≥n cruzada exhaustiva
- Pruebas en casos extremos (edge cases)
- Evaluaci√≥n de sesgo y equidad
- Auditor√≠as de seguridad
- Verificaci√≥n de rendimiento en datos de retenci√≥n

**b) Despliegue del Modelo**
- Empaquetar el modelo con sus dependencias
- Configurar infraestructura de producci√≥n
- Implementar APIs de servicio (REST, gRPC)
- Establecer estrategias de despliegue (blue-green, canary)
- Garantizar reproducibilidad del entorno

**c) Integraci√≥n y Entrega Continua (CI/CD)**
- Automatizar pipelines de entrenamiento
- Implementar pruebas automatizadas
- Validar datos y modelos autom√°ticamente
- Desplegar servicios de predicci√≥n autom√°ticamente

#### 1.2.3 Fase de Monitoreo

Esta fase asegura que el modelo contin√∫e funcionando correctamente:

**a) Monitoreo de Rendimiento**
- Supervisar m√©tricas de negocio (precisi√≥n, recall, F1-score)
- Monitorear latencia y throughput
- Detectar anomal√≠as en predicciones
- Rastrear uso de recursos computacionales

**b) Detecci√≥n de Drift**
- **Data Drift**: Cambios en la distribuci√≥n de datos de entrada
- **Concept Drift**: Cambios en la relaci√≥n entre caracter√≠sticas y objetivo
- **Prediction Drift**: Cambios en la distribuci√≥n de predicciones

**c) Reentrenamiento Continuo (CT)**
- Programar reentrenamiento peri√≥dico
- Activar reentrenamiento basado en degradaci√≥n de rendimiento
- Incorporar nuevos datos autom√°ticamente
- Validar modelos reentrenados antes de despliegue

### 1.3 Principios Fundamentales de MLOps

#### 1.3.1 Versionado Integral

El versionado en MLOps va m√°s all√° del c√≥digo fuente:

- **C√≥digo**: Control de versiones del c√≥digo de entrenamiento, preprocesamiento y servicio
- **Datos**: Versionado de datasets, incluyendo datos de entrenamiento, validaci√≥n y prueba
- **Modelos**: Registro de versiones de modelos con sus metadatos
- **Configuraciones**: Versionado de hiperpar√°metros y configuraciones de entrenamiento
- **Entornos**: Definiciones de entornos (contenedores, dependencias)

#### 1.3.2 Automatizaci√≥n

La automatizaci√≥n es esencial para la eficiencia y consistencia:

- **Pipelines de Datos**: Automatizar extracci√≥n, transformaci√≥n y carga (ETL)
- **Entrenamiento**: Automatizar el proceso de entrenamiento con diferentes configuraciones
- **Validaci√≥n**: Pruebas automatizadas de calidad de datos y modelos
- **Despliegue**: Despliegue autom√°tico tras validaci√≥n exitosa
- **Monitoreo**: Alertas autom√°ticas ante degradaci√≥n de rendimiento

#### 1.3.3 Reproducibilidad

Capacidad de recrear exactamente los mismos resultados:

- Fijar semillas aleatorias (random seeds)
- Documentar versiones de bibliotecas y frameworks
- Registrar configuraciones de hardware
- Mantener trazabilidad completa de experimentos
- Usar contenedores para aislar entornos

#### 1.3.4 Experimentaci√≥n Sistem√°tica

Gesti√≥n organizada de experimentos de ML:

- Registro de hiperpar√°metros utilizados
- Almacenamiento de m√©tricas de rendimiento
- Comparaci√≥n de resultados entre experimentos
- Documentaci√≥n de decisiones y hallazgos
- Trazabilidad desde experimento hasta producci√≥n

#### 1.3.5 Monitoreo y Observabilidad

Visibilidad completa del sistema de ML en producci√≥n:

- M√©tricas de rendimiento del modelo
- M√©tricas de infraestructura (CPU, memoria, latencia)
- Logging estructurado de predicciones
- Dashboards de monitoreo en tiempo real
- Alertas configurables

### 1.4 Desaf√≠os que Aborda MLOps

#### 1.4.1 Gesti√≥n de Experimentos

**Problema**: Los cient√≠ficos de datos ejecutan cientos de experimentos con diferentes hiperpar√°metros, datasets y algoritmos, perdiendo f√°cilmente el rastro de qu√© funcion√≥ y por qu√©.

**Soluci√≥n MLOps**: Sistemas de tracking que registran autom√°ticamente todos los par√°metros, m√©tricas y artefactos de cada experimento, permitiendo comparaciones y reproducibilidad.

#### 1.4.2 Brecha entre Desarrollo y Producci√≥n

**Problema**: Los modelos que funcionan bien en notebooks de Jupyter fallan o tienen bajo rendimiento en producci√≥n debido a diferencias en datos, entornos o escalabilidad.

**Soluci√≥n MLOps**: Pipelines automatizados que garantizan consistencia entre desarrollo y producci√≥n, con validaci√≥n rigurosa antes del despliegue.

#### 1.4.3 Degradaci√≥n del Modelo

**Problema**: Los modelos de ML pueden degradarse con el tiempo debido a cambios en los datos (drift), sin que los equipos lo detecten hasta que afecta el negocio.

**Soluci√≥n MLOps**: Monitoreo continuo de rendimiento y drift, con reentrenamiento autom√°tico cuando se detecta degradaci√≥n.

#### 1.4.4 Escalabilidad

**Problema**: Entrenar y servir modelos a gran escala requiere infraestructura especializada y optimizaci√≥n cuidadosa.

**Soluci√≥n MLOps**: Uso de contenedores, orquestaci√≥n (Kubernetes), y servicios cloud que permiten escalar horizontal y verticalmente seg√∫n demanda.

#### 1.4.5 Colaboraci√≥n

**Problema**: Cient√≠ficos de datos, ingenieros de ML y equipos de operaciones trabajan en silos, dificultando la comunicaci√≥n y el despliegue eficiente.

**Soluci√≥n MLOps**: Plataformas centralizadas, documentaci√≥n compartida, y procesos estandarizados que facilitan la colaboraci√≥n interdisciplinaria.

#### 1.4.6 Cumplimiento y Gobernanza

**Problema**: Regulaciones como GDPR requieren explicabilidad, auditor√≠a y trazabilidad de modelos de ML.

**Soluci√≥n MLOps**: Registro completo de linaje de modelos, versionado, y documentaci√≥n que permite auditor√≠as y cumplimiento regulatorio.

### 1.5 MLOps vs DevOps

Aunque MLOps se inspira en DevOps, existen diferencias fundamentales:

| Aspecto | DevOps | MLOps |
|---------|--------|-------|
| **Artefacto Principal** | C√≥digo fuente | C√≥digo + Datos + Modelos |
| **Testing** | Pruebas unitarias, integraci√≥n | Validaci√≥n de datos, evaluaci√≥n de modelos, detecci√≥n de drift |
| **Versionado** | C√≥digo | C√≥digo + Datos + Modelos + Configuraciones |
| **Despliegue** | Aplicaci√≥n est√°tica | Modelo que puede degradarse con el tiempo |
| **Monitoreo** | M√©tricas de sistema (uptime, latencia) | M√©tricas de sistema + M√©tricas de modelo (precisi√≥n, drift) |
| **Reentrenamiento** | No aplica | Reentrenamiento continuo (CT) |
| **Experimentaci√≥n** | Limitada | Extensiva y sistem√°tica |
| **Dependencias** | Bibliotecas de software | Bibliotecas + Datos + Hardware espec√≠fico |

**Elementos √önicos de MLOps:**

1. **Continuous Training (CT)**: Adem√°s de CI/CD, MLOps incluye reentrenamiento autom√°tico de modelos
2. **Data Validation**: Validaci√≥n rigurosa de calidad e integridad de datos
3. **Model Monitoring**: Supervisi√≥n de rendimiento predictivo, no solo operacional
4. **Feature Store**: Gesti√≥n centralizada de caracter√≠sticas para consistencia entre entrenamiento e inferencia
5. **Model Registry**: Repositorio centralizado de modelos con versionado y gesti√≥n de ciclo de vida

---

## 2. Consideraciones T√©cnicas

### 2.1 Introducci√≥n a MLflow

**MLflow** es una plataforma open-source desarrollada por Databricks que facilita la gesti√≥n del ciclo de vida completo de machine learning. Proporciona una interfaz unificada para experimentaci√≥n, reproducibilidad, despliegue y gesti√≥n de modelos.

#### Caracter√≠sticas Principales:

- **Open Source**: C√≥digo abierto con comunidad activa
- **Agn√≥stico de Framework**: Funciona con cualquier biblioteca de ML (scikit-learn, TensorFlow, PyTorch, XGBoost, etc.)
- **Agn√≥stico de Plataforma**: Ejecutable localmente, en servidores on-premise, o en la nube
- **Interfaz Unificada**: API consistente en Python, R, Java y REST
- **Extensible**: Permite plugins y personalizaciones

#### ¬øPor qu√© MLflow?

1. **Simplicidad**: F√°cil de instalar y comenzar a usar
2. **Flexibilidad**: No impone una estructura r√≠gida de trabajo
3. **Interoperabilidad**: Se integra con herramientas existentes
4. **Escalabilidad**: Desde experimentos locales hasta producci√≥n a gran escala
5. **Comunidad**: Amplia adopci√≥n en la industria

### 2.2 Componentes de MLflow

MLflow est√° compuesto por cuatro componentes principales que abordan diferentes aspectos del ciclo de vida de ML:

![MLflow Components](./images/componentes.png)

#### 2.2.1 MLflow Tracking

**Prop√≥sito**: Registrar y consultar experimentos, incluyendo par√°metros, m√©tricas, c√≥digo y artefactos.

**Conceptos Clave:**

- **Run**: Una ejecuci√≥n individual de c√≥digo de ML
- **Experiment**: Agrupaci√≥n de runs relacionados
- **Parameters**: Valores de entrada (hiperpar√°metros)
- **Metrics**: Valores de salida cuantitativos (precisi√≥n, p√©rdida)
- **Artifacts**: Archivos de salida (modelos, gr√°ficos, datos)
- **Tags**: Metadatos adicionales para organizaci√≥n

**Funcionalidades:**

```python
import mlflow

# Iniciar un experimento
mlflow.set_experiment("customer_churn_prediction")

# Registrar un run
with mlflow.start_run():
    # Registrar par√°metros
    mlflow.log_param("learning_rate", 0.01)
    mlflow.log_param("max_depth", 5)
    
    # Entrenar modelo
    model = train_model(learning_rate=0.01, max_depth=5)
    
    # Registrar m√©tricas
    mlflow.log_metric("accuracy", 0.92)
    mlflow.log_metric("f1_score", 0.89)
    
    # Registrar artefactos
    mlflow.log_artifact("confusion_matrix.png")
    mlflow.sklearn.log_model(model, "model")
```

**Interfaz de Usuario:**

MLflow proporciona una UI web interactiva para:
- Comparar runs lado a lado
- Visualizar m√©tricas a lo largo del tiempo
- Buscar y filtrar experimentos
- Descargar artefactos
- Analizar tendencias

**Almacenamiento:**

- **Backend Store**: Almacena metadatos (par√°metros, m√©tricas, tags)
  - Opciones: Sistema de archivos local, PostgreSQL, MySQL, SQLite
- **Artifact Store**: Almacena artefactos (modelos, archivos)
  - Opciones: Sistema de archivos local, Amazon S3, Azure Blob Storage, Google Cloud Storage

#### 2.2.2 MLflow Projects

**Prop√≥sito**: Empaquetar c√≥digo de ML en un formato reutilizable y reproducible.

**Estructura de un Proyecto:**

```
my_ml_project/
‚îú‚îÄ‚îÄ MLproject          # Archivo de configuraci√≥n
‚îú‚îÄ‚îÄ conda.yaml         # Dependencias del entorno
‚îú‚îÄ‚îÄ train.py           # C√≥digo de entrenamiento
‚îî‚îÄ‚îÄ predict.py         # C√≥digo de predicci√≥n
```

**Archivo MLproject:**

```yaml
name: Customer Churn Prediction

conda_env: conda.yaml

entry_points:
  main:
    parameters:
      learning_rate: {type: float, default: 0.01}
      max_depth: {type: int, default: 5}
    command: "python train.py --learning-rate {learning_rate} --max-depth {max_depth}"
  
  predict:
    parameters:
      model_uri: {type: string}
      data_path: {type: string}
    command: "python predict.py --model-uri {model_uri} --data-path {data_path}"
```

**Ejecuci√≥n:**

```bash
# Ejecutar localmente
mlflow run . -P learning_rate=0.01 -P max_depth=5

# Ejecutar desde GitHub
mlflow run https://github.com/user/repo -P learning_rate=0.01

# Ejecutar en Kubernetes
mlflow run . --backend kubernetes --backend-config kubernetes_config.json
```

**Beneficios:**

- Reproducibilidad garantizada mediante gesti√≥n de entornos
- Facilita compartir c√≥digo con el equipo
- Permite ejecuci√≥n en diferentes plataformas
- Integraci√≥n con sistemas de CI/CD

#### 2.2.3 MLflow Models

**Prop√≥sito**: Formato est√°ndar para empaquetar modelos de ML que permite despliegue en m√∫ltiples plataformas.

**Estructura de un Modelo:**

```
model/
‚îú‚îÄ‚îÄ MLmodel              # Descriptor del modelo
‚îú‚îÄ‚îÄ conda.yaml           # Dependencias
‚îú‚îÄ‚îÄ python_env.yaml      # Entorno Python
‚îú‚îÄ‚îÄ requirements.txt     # Requisitos pip
‚îî‚îÄ‚îÄ model.pkl            # Modelo serializado
```

**Archivo MLmodel:**

```yaml
artifact_path: model
flavors:
  python_function:
    env:
      conda: conda.yaml
      virtualenv: python_env.yaml
    loader_module: mlflow.sklearn
    model_path: model.pkl
    predict_fn: predict
    python_version: 3.9.0
  sklearn:
    code: null
    pickled_model: model.pkl
    serialization_format: cloudpickle
    sklearn_version: 1.3.0
mlflow_version: 2.8.0
model_uuid: 7a8b9c0d1e2f3g4h5i6j7k8l9m0n1o2p
signature:
  inputs: '[{"name": "age", "type": "long"}, {"name": "income", "type": "double"}]'
  outputs: '[{"type": "long"}]'
```

**Flavors (Sabores):**

MLflow soporta m√∫ltiples "flavors" que permiten usar el modelo con diferentes herramientas:

- `python_function`: Interfaz gen√©rica de Python
- `sklearn`: Modelos de scikit-learn
- `tensorflow`: Modelos de TensorFlow
- `pytorch`: Modelos de PyTorch
- `xgboost`: Modelos de XGBoost
- `h2o`: Modelos de H2O
- `spark`: Modelos de Spark MLlib

**Despliegue:**

```bash
# Servir modelo como API REST
mlflow models serve -m models:/customer_churn/production -p 5000

# Desplegar en AWS SageMaker
mlflow deployments create -t sagemaker -m models:/customer_churn/production

# Desplegar en Azure ML
mlflow deployments create -t azureml -m models:/customer_churn/production

# Generar imagen Docker
mlflow models build-docker -m models:/customer_churn/production -n churn-model
```

**Model Signature:**

Define el esquema de entrada y salida del modelo:

```python
from mlflow.models.signature import infer_signature

# Inferir signature autom√°ticamente
signature = infer_signature(X_train, model.predict(X_train))

# Registrar modelo con signature
mlflow.sklearn.log_model(model, "model", signature=signature)
```

#### 2.2.4 MLflow Model Registry

**Prop√≥sito**: Almac√©n centralizado para gestionar el ciclo de vida completo de modelos MLflow.

**Conceptos Clave:**

- **Registered Model**: Nombre √∫nico para un modelo
- **Model Version**: Versi√≥n espec√≠fica de un modelo registrado
- **Model Stage**: Etapa del ciclo de vida (None, Staging, Production, Archived)
- **Model Alias**: Nombre alternativo para una versi√≥n espec√≠fica
- **Annotations**: Descripciones y metadatos

**Flujo de Trabajo:**

![MLflow Model Registry Workflow](./images/model_registry.png)

**Operaciones Principales:**

```python
import mlflow
from mlflow.tracking import MlflowClient

client = MlflowClient()

# Registrar un modelo
model_uri = f"runs:/{run_id}/model"
model_details = mlflow.register_model(model_uri, "customer_churn_model")

# Transicionar a Staging
client.transition_model_version_stage(
    name="customer_churn_model",
    version=1,
    stage="Staging"
)

# A√±adir descripci√≥n
client.update_model_version(
    name="customer_churn_model",
    version=1,
    description="Random Forest model with 95% accuracy on test set"
)

# Transicionar a Production
client.transition_model_version_stage(
    name="customer_churn_model",
    version=1,
    stage="Production"
)

# Cargar modelo desde Registry
model = mlflow.pyfunc.load_model("models:/customer_churn_model/production")
predictions = model.predict(data)

# Crear alias
client.set_registered_model_alias("customer_churn_model", "champion", 1)

# Cargar por alias
model = mlflow.pyfunc.load_model("models:/customer_churn_model@champion")
```

**Beneficios:**

- **Versionado Autom√°tico**: Cada registro crea una nueva versi√≥n
- **Gesti√≥n de Ciclo de Vida**: Control de etapas de desarrollo
- **Trazabilidad**: Linaje completo desde experimento hasta producci√≥n
- **Colaboraci√≥n**: Equipo completo puede ver y gestionar modelos
- **Gobernanza**: Control de acceso y auditor√≠a (con backends apropiados)

### 2.3 Instalaci√≥n y Configuraci√≥n

#### 2.3.1 Instalaci√≥n B√°sica

**Requisitos:**
- Python 3.8 o superior
- pip o conda

**Instalaci√≥n con pip:**

```bash
pip install mlflow
```

**Instalaci√≥n con conda:**

```bash
conda install -c conda-forge mlflow
```

**Instalaci√≥n con dependencias adicionales:**

```bash
# Con soporte para PostgreSQL
pip install mlflow[extras]

# Con todas las dependencias
pip install mlflow[extras] psycopg2-binary boto3 google-cloud-storage azure-storage-blob
```

#### 2.3.2 Configuraci√≥n Local

**Iniciar MLflow UI:**

```bash
# Usar almacenamiento local por defecto
mlflow ui

# Especificar puerto
mlflow ui --port 5001

# Especificar directorio de backend
mlflow ui --backend-store-uri file:///path/to/mlruns
```

La UI estar√° disponible en `http://localhost:5000`

#### 2.3.3 Configuraci√≥n con Base de Datos

**PostgreSQL Backend:**

```bash
# Instalar driver
pip install psycopg2-binary

# Iniciar servidor MLflow
mlflow server \
    --backend-store-uri postgresql://user:password@localhost/mlflow_db \
    --default-artifact-root s3://my-mlflow-bucket/ \
    --host 0.0.0.0 \
    --port 5000
```

**MySQL Backend:**

```bash
# Instalar driver
pip install pymysql

# Iniciar servidor
mlflow server \
    --backend-store-uri mysql+pymysql://user:password@localhost/mlflow_db \
    --default-artifact-root /mnt/mlflow-artifacts \
    --host 0.0.0.0
```

#### 2.3.4 Configuraci√≥n con Almacenamiento en la Nube

**Amazon S3:**

```bash
# Configurar credenciales AWS
export AWS_ACCESS_KEY_ID=your_access_key
export AWS_SECRET_ACCESS_KEY=your_secret_key

# Iniciar servidor
mlflow server \
    --backend-store-uri postgresql://user:password@localhost/mlflow_db \
    --default-artifact-root s3://my-mlflow-bucket/artifacts
```

**Azure Blob Storage:**

```bash
# Configurar credenciales Azure
export AZURE_STORAGE_CONNECTION_STRING=your_connection_string

# Iniciar servidor
mlflow server \
    --backend-store-uri postgresql://user:password@localhost/mlflow_db \
    --default-artifact-root wasbs://container@account.blob.core.windows.net/path
```

**Google Cloud Storage:**

```bash
# Configurar credenciales GCP
export GOOGLE_APPLICATION_CREDENTIALS=/path/to/credentials.json

# Iniciar servidor
mlflow server \
    --backend-store-uri postgresql://user:password@localhost/mlflow_db \
    --default-artifact-root gs://my-mlflow-bucket/artifacts
```

#### 2.3.5 Configuraci√≥n de Cliente

**En c√≥digo Python:**

```python
import mlflow

# Conectar a servidor remoto
mlflow.set_tracking_uri("http://mlflow-server:5000")

# Usar almacenamiento local
mlflow.set_tracking_uri("file:///path/to/mlruns")

# Usar base de datos
mlflow.set_tracking_uri("postgresql://user:password@localhost/mlflow_db")
```

**Variables de entorno:**

```bash
# URI del servidor de tracking
export MLFLOW_TRACKING_URI=http://mlflow-server:5000

# Ubicaci√≥n de artefactos
export MLFLOW_ARTIFACT_ROOT=s3://my-bucket/artifacts

# Nombre de experimento por defecto
export MLFLOW_EXPERIMENT_NAME=my_experiment
```

#### 2.3.6 Mejores Pr√°cticas de Configuraci√≥n

1. **Separar Backend y Artifact Store**: Usar base de datos para metadatos y almacenamiento en la nube para artefactos
2. **Backup Regular**: Implementar respaldos autom√°ticos de la base de datos
3. **Control de Acceso**: Configurar autenticaci√≥n y autorizaci√≥n (usando proxies o Databricks)
4. **Escalabilidad**: Usar bases de datos escalables (PostgreSQL, MySQL) en lugar de SQLite para producci√≥n
5. **Monitoreo**: Supervisar uso de almacenamiento y rendimiento del servidor
6. **Networking**: Configurar firewalls y VPNs apropiadamente para acceso seguro

### 2.4 Integraci√≥n con Frameworks de ML

MLflow se integra nativamente con los frameworks de ML m√°s populares:

#### 2.4.1 Scikit-learn

```python
import mlflow
import mlflow.sklearn
from sklearn.ensemble import RandomForestClassifier

mlflow.set_experiment("sklearn_experiment")

with mlflow.start_run():
    # Entrenar modelo
    model = RandomForestClassifier(n_estimators=100, max_depth=5)
    model.fit(X_train, y_train)
    
    # Autologging (registra autom√°ticamente par√°metros y m√©tricas)
    mlflow.sklearn.autolog()
    
    # O logging manual
    mlflow.log_param("n_estimators", 100)
    mlflow.log_metric("accuracy", model.score(X_test, y_test))
    mlflow.sklearn.log_model(model, "model")
```

#### 2.4.2 TensorFlow / Keras

```python
import mlflow
import mlflow.tensorflow
import tensorflow as tf

mlflow.tensorflow.autolog()

with mlflow.start_run():
    model = tf.keras.Sequential([
        tf.keras.layers.Dense(64, activation='relu'),
        tf.keras.layers.Dense(10, activation='softmax')
    ])
    
    model.compile(optimizer='adam', loss='sparse_categorical_crossentropy')
    model.fit(X_train, y_train, epochs=10, validation_data=(X_val, y_val))
    
    # Autolog registra autom√°ticamente arquitectura, par√°metros y m√©tricas
```

#### 2.4.3 PyTorch

```python
import mlflow
import mlflow.pytorch
import torch

mlflow.pytorch.autolog()

with mlflow.start_run():
    model = MyNeuralNetwork()
    optimizer = torch.optim.Adam(model.parameters())
    
    for epoch in range(num_epochs):
        train_loss = train_epoch(model, train_loader, optimizer)
        val_loss = validate(model, val_loader)
        
        mlflow.log_metric("train_loss", train_loss, step=epoch)
        mlflow.log_metric("val_loss", val_loss, step=epoch)
    
    mlflow.pytorch.log_model(model, "model")
```

#### 2.4.4 XGBoost

```python
import mlflow
import mlflow.xgboost
import xgboost as xgb

mlflow.xgboost.autolog()

with mlflow.start_run():
    dtrain = xgb.DMatrix(X_train, label=y_train)
    dtest = xgb.DMatrix(X_test, label=y_test)
    
    params = {
        'max_depth': 6,
        'eta': 0.1,
        'objective': 'binary:logistic'
    }
    
    model = xgb.train(params, dtrain, num_boost_round=100)
    mlflow.xgboost.log_model(model, "model")
```

### 2.5 Estrategias de Despliegue

MLflow facilita m√∫ltiples estrategias de despliegue:

#### 2.5.1 Servicio REST Local

```bash
# Servir modelo localmente
mlflow models serve -m models:/customer_churn/production -p 5000 --no-conda

# Hacer predicciones
curl -X POST http://localhost:5000/invocations \
  -H 'Content-Type: application/json' \
  -d '{"dataframe_split": {"columns": ["age", "income"], "data": [[25, 50000]]}}'
```

#### 2.5.2 Contenedores Docker

```bash
# Construir imagen Docker
mlflow models build-docker -m models:/customer_churn/production -n churn-model

# Ejecutar contenedor
docker run -p 5000:8080 churn-model

# Desplegar en Kubernetes
kubectl apply -f deployment.yaml
```

#### 2.5.3 Despliegue en Cloud

**AWS SageMaker:**

```python
import mlflow.sagemaker as mfs

mfs.deploy(
    app_name="churn-prediction",
    model_uri="models:/customer_churn/production",
    region_name="us-west-2",
    mode="create",
    execution_role_arn="arn:aws:iam::123456789:role/SageMakerRole"
)
```

**Azure ML:**

```python
import mlflow.azureml as maz

maz.deploy(
    model_uri="models:/customer_churn/production",
    workspace=workspace,
    deployment_config=deployment_config
)
```

#### 2.5.4 Batch Inference

```python
import mlflow

# Cargar modelo
model = mlflow.pyfunc.load_model("models:/customer_churn/production")

# Predicciones en lote
predictions = model.predict(large_dataset)
```

---

## 3. Demostraci√≥n Pr√°ctica

### 3.1 Escenario de Aplicaci√≥n

#### Contexto del Problema

La demostraci√≥n implementa un sistema de **predicci√≥n de abandono de clientes (customer churn)** para una empresa de telecomunicaciones. El objetivo es identificar clientes con alta probabilidad de cancelar su servicio, permitiendo a la empresa tomar acciones preventivas.

#### Objetivos de la Demo

1. Demostrar el uso de **MLflow Tracking** para gestionar experimentos
2. Comparar m√∫ltiples algoritmos de ML (Logistic Regression, Random Forest, XGBoost)
3. Realizar **ajuste de hiperpar√°metros** con tracking completo
4. Utilizar **MLflow Model Registry** para gestionar versiones de modelos
5. Mostrar el flujo completo desde experimentaci√≥n hasta "producci√≥n"

#### Dataset

Se utiliza un dataset p√∫blico de churn de telecomunicaciones que incluye:
- **Caracter√≠sticas demogr√°ficas**: edad, g√©nero, estado civil
- **Caracter√≠sticas de servicio**: tipo de contrato, m√©todo de pago, servicios contratados
- **Caracter√≠sticas de uso**: duraci√≥n del servicio, cargos mensuales, cargos totales
- **Variable objetivo**: si el cliente abandon√≥ o no (churn)

### 3.2 Arquitectura de la Demo

![Demo Architecture](./images/arquitectura_demo.png)

### 3.3 Implementaci√≥n

La implementaci√≥n completa se encuentra en el directorio `demo/` del repositorio. A continuaci√≥n se presentan los componentes clave:

#### 3.3.1 Estructura del Proyecto

```
demo/
‚îú‚îÄ‚îÄ README.md                           # Documentaci√≥n de la demo
‚îú‚îÄ‚îÄ requirements.txt                    # Dependencias Python
‚îú‚îÄ‚îÄ data/
‚îÇ   ‚îî‚îÄ‚îÄ download_data.py               # Script para obtener datos
‚îú‚îÄ‚îÄ src/
‚îÇ   ‚îú‚îÄ‚îÄ train.py                       # Entrenamiento de modelos
‚îÇ   ‚îú‚îÄ‚îÄ hyperparameter_tuning.py       # Optimizaci√≥n de hiperpar√°metros
‚îÇ   ‚îú‚îÄ‚îÄ evaluate.py                    # Evaluaci√≥n de modelos
‚îÇ   ‚îî‚îÄ‚îÄ utils.py                       # Funciones auxiliares
‚îî‚îÄ‚îÄ notebooks/
    ‚îî‚îÄ‚îÄ exploratory_analysis.ipynb     # An√°lisis exploratorio
```

#### 3.3.2 Flujo de Trabajo

**Paso 1: Preparaci√≥n de Datos**

```python
# src/utils.py
import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler, LabelEncoder

def load_and_preprocess_data(data_path):
    """Carga y preprocesa el dataset de churn"""
    df = pd.read_csv(data_path)
    
    # Codificar variables categ√≥ricas
    le = LabelEncoder()
    categorical_cols = df.select_dtypes(include=['object']).columns
    
    for col in categorical_cols:
        if col != 'Churn':
            df[col] = le.fit_transform(df[col])
    
    # Separar caracter√≠sticas y objetivo
    X = df.drop('Churn', axis=1)
    y = le.fit_transform(df['Churn'])
    
    # Split train/test
    X_train, X_test, y_train, y_test = train_test_split(
        X, y, test_size=0.2, random_state=42, stratify=y
    )
    
    # Normalizar caracter√≠sticas
    scaler = StandardScaler()
    X_train_scaled = scaler.fit_transform(X_train)
    X_test_scaled = scaler.transform(X_test)
    
    return X_train_scaled, X_test_scaled, y_train, y_test, scaler
```

**Paso 2: Entrenamiento con MLflow Tracking**

```python
# src/train.py
import mlflow
import mlflow.sklearn
from sklearn.linear_model import LogisticRegression
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score
import xgboost as xgb

def train_and_log_model(model, model_name, X_train, X_test, y_train, y_test):
    """Entrena modelo y registra en MLflow"""
    
    with mlflow.start_run(run_name=model_name):
        # Entrenar modelo
        model.fit(X_train, y_train)
        
        # Predicciones
        y_pred = model.predict(X_test)
        
        # Calcular m√©tricas
        accuracy = accuracy_score(y_test, y_pred)
        precision = precision_score(y_test, y_pred)
        recall = recall_score(y_test, y_pred)
        f1 = f1_score(y_test, y_pred)
        
        # Registrar par√°metros
        mlflow.log_params(model.get_params())
        
        # Registrar m√©tricas
        mlflow.log_metric("accuracy", accuracy)
        mlflow.log_metric("precision", precision)
        mlflow.log_metric("recall", recall)
        mlflow.log_metric("f1_score", f1)
        
        # Registrar modelo
        mlflow.sklearn.log_model(model, "model")
        
        print(f"{model_name} - Accuracy: {accuracy:.4f}, F1: {f1:.4f}")
        
        return mlflow.active_run().info.run_id

# Configurar experimento
mlflow.set_experiment("customer_churn_prediction")

# Entrenar m√∫ltiples modelos
models = {
    "Logistic_Regression": LogisticRegression(max_iter=1000),
    "Random_Forest": RandomForestClassifier(n_estimators=100, random_state=42),
    "XGBoost": xgb.XGBClassifier(n_estimators=100, random_state=42)
}

for name, model in models.items():
    train_and_log_model(model, name, X_train, X_test, y_train, y_test)
```

**Paso 3: Ajuste de Hiperpar√°metros**

```python
# src/hyperparameter_tuning.py
import mlflow
from sklearn.model_selection import GridSearchCV
from sklearn.ensemble import RandomForestClassifier

def hyperparameter_tuning(X_train, y_train, X_test, y_test):
    """Realiza grid search con tracking en MLflow"""
    
    mlflow.set_experiment("customer_churn_hyperparameter_tuning")
    
    param_grid = {
        'n_estimators': [50, 100, 200],
        'max_depth': [5, 10, 15, None],
        'min_samples_split': [2, 5, 10]
    }
    
    rf = RandomForestClassifier(random_state=42)
    grid_search = GridSearchCV(rf, param_grid, cv=5, scoring='f1', n_jobs=-1)
    
    # Registrar cada combinaci√≥n
    for params in grid_search.cv_results_['params']:
        with mlflow.start_run():
            model = RandomForestClassifier(**params, random_state=42)
            model.fit(X_train, y_train)
            
            y_pred = model.predict(X_test)
            f1 = f1_score(y_test, y_pred)
            
            mlflow.log_params(params)
            mlflow.log_metric("f1_score", f1)
            mlflow.sklearn.log_model(model, "model")
    
    grid_search.fit(X_train, y_train)
    
    # Registrar mejor modelo
    with mlflow.start_run(run_name="best_model"):
        best_model = grid_search.best_estimator_
        y_pred = best_model.predict(X_test)
        
        mlflow.log_params(grid_search.best_params_)
        mlflow.log_metric("f1_score", f1_score(y_test, y_pred))
        mlflow.log_metric("accuracy", accuracy_score(y_test, y_pred))
        mlflow.sklearn.log_model(best_model, "model")
        
        return mlflow.active_run().info.run_id
```

**Paso 4: Registro en Model Registry**

```python
# Registrar mejor modelo
model_uri = f"runs:/{best_run_id}/model"
model_details = mlflow.register_model(model_uri, "customer_churn_predictor")

# Transicionar a Staging
client = MlflowClient()
client.transition_model_version_stage(
    name="customer_churn_predictor",
    version=model_details.version,
    stage="Staging"
)

# A√±adir descripci√≥n
client.update_model_version(
    name="customer_churn_predictor",
    version=model_details.version,
    description="Random Forest model with optimized hyperparameters. F1-score: 0.89"
)
```

**Paso 5: Evaluaci√≥n y Promoci√≥n a Producci√≥n**

```python
# src/evaluate.py
def evaluate_staged_model(model_name, stage, X_test, y_test):
    """Eval√∫a modelo en una etapa espec√≠fica"""
    
    model_uri = f"models:/{model_name}/{stage}"
    model = mlflow.pyfunc.load_model(model_uri)
    
    y_pred = model.predict(X_test)
    
    metrics = {
        "accuracy": accuracy_score(y_test, y_pred),
        "precision": precision_score(y_test, y_pred),
        "recall": recall_score(y_test, y_pred),
        "f1_score": f1_score(y_test, y_pred)
    }
    
    print(f"Model: {model_name} ({stage})")
    for metric, value in metrics.items():
        print(f"  {metric}: {value:.4f}")
    
    return metrics

# Evaluar modelo en Staging
staging_metrics = evaluate_staged_model("customer_churn_predictor", "Staging", X_test, y_test)

# Si las m√©tricas son satisfactorias, promover a Production
if staging_metrics['f1_score'] > 0.85:
    client.transition_model_version_stage(
        name="customer_churn_predictor",
        version=model_details.version,
        stage="Production"
    )
    print("Model promoted to Production!")
```

### 3.4 Resultados y An√°lisis

#### 3.4.1 Comparaci√≥n de Modelos

Los experimentos realizados mostraron los siguientes resultados:

| Modelo | Accuracy | Precision | Recall | F1-Score |
|--------|----------|-----------|--------|----------|
| Logistic Regression | 0.7845 | 0.6523 | 0.5891 | 0.6189 |
| Random Forest (default) | 0.8234 | 0.7456 | 0.6789 | 0.7105 |
| XGBoost (default) | 0.8312 | 0.7623 | 0.6945 | 0.7267 |
| **Random Forest (tuned)** | **0.8567** | **0.8012** | **0.7534** | **0.7765** |

El modelo Random Forest con hiperpar√°metros optimizados mostr√≥ el mejor desempe√±o, logrando un F1-score de 0.7765.

#### 3.4.2 Hiperpar√°metros √ìptimos

```python
{
    'n_estimators': 200,
    'max_depth': 15,
    'min_samples_split': 2,
    'random_state': 42
}
```

#### 3.4.3 Insights del MLflow UI

La interfaz de MLflow permiti√≥:

1. **Comparaci√≥n Visual**: Visualizar m√©tricas de todos los experimentos lado a lado
2. **An√°lisis de Tendencias**: Identificar c√≥mo diferentes hiperpar√°metros afectan el rendimiento
3. **Reproducibilidad**: Acceder a todos los par√°metros y artefactos de cada run
4. **Trazabilidad**: Seguir el linaje desde experimento hasta modelo en producci√≥n

#### 3.4.4 Lecciones Aprendidas

1. **Tracking Autom√°tico**: El autologging de MLflow simplifica significativamente el proceso de experimentaci√≥n
2. **Gesti√≥n de Versiones**: El Model Registry facilita la colaboraci√≥n y el control de versiones
3. **Reproducibilidad**: La capacidad de recrear exactamente cualquier experimento es invaluable
4. **Escalabilidad**: La arquitectura de MLflow permite escalar desde experimentos locales hasta producci√≥n

---

## 4. Conclusiones

MLOps representa un cambio paradigm√°tico en c√≥mo se desarrollan, despliegan y mantienen sistemas de Machine Learning en producci√≥n. A trav√©s de este informe, hemos explorado:

### 4.1 Conceptos Fundamentales

- MLOps extiende los principios de DevOps al dominio de ML, abordando desaf√≠os √∫nicos como el versionado de datos, la gesti√≥n de experimentos y el monitoreo de drift
- El ciclo de vida de MLOps (Experimental, Producci√≥n, Monitoreo) requiere herramientas especializadas para cada fase
- Los principios de automatizaci√≥n, reproducibilidad y monitoreo continuo son esenciales para el √©xito de MLOps

### 4.2 MLflow como Plataforma MLOps

- **MLflow Tracking** proporciona una soluci√≥n robusta para la gesti√≥n de experimentos, permitiendo comparar cientos de runs y mantener trazabilidad completa
- **MLflow Projects** garantiza reproducibilidad mediante el empaquetado estandarizado de c√≥digo y dependencias
- **MLflow Models** facilita el despliegue multi-plataforma con un formato de modelo unificado
- **MLflow Model Registry** centraliza la gesti√≥n del ciclo de vida de modelos, desde desarrollo hasta producci√≥n

### 4.3 Valor Pr√°ctico

La demostraci√≥n pr√°ctica de predicci√≥n de churn ilustr√≥ c√≥mo MLflow:
- Simplifica la experimentaci√≥n con m√∫ltiples algoritmos y configuraciones
- Facilita la colaboraci√≥n mediante un repositorio centralizado de experimentos
- Acelera el tiempo de despliegue con herramientas de empaquetado y servicio
- Proporciona trazabilidad completa desde experimento hasta producci√≥n

### 4.4 Recomendaciones

Para equipos que buscan implementar MLOps:

1. **Comenzar Simple**: Iniciar con MLflow Tracking para gestionar experimentos antes de adoptar componentes m√°s avanzados
2. **Establecer Est√°ndares**: Definir convenciones de nomenclatura, estructura de proyectos y m√©tricas clave
3. **Automatizar Gradualmente**: Implementar CI/CD para ML de manera incremental
4. **Monitorear Proactivamente**: Establecer alertas para degradaci√≥n de modelos desde el inicio
5. **Fomentar Colaboraci√≥n**: Usar herramientas centralizadas para facilitar comunicaci√≥n entre equipos

### 4.5 Perspectivas Futuras

El campo de MLOps contin√∫a evolucionando con tendencias emergentes como:
- **AutoML y MLOps**: Integraci√≥n de automatizaci√≥n de ML con pr√°cticas de MLOps
- **MLOps en Edge**: Despliegue y gesti√≥n de modelos en dispositivos edge
- **Responsible AI**: Incorporaci√≥n de explicabilidad, equidad y privacidad en pipelines de MLOps
- **Feature Stores**: Gesti√≥n centralizada de caracter√≠sticas para consistencia entre entrenamiento e inferencia
- **Continuous Training**: Reentrenamiento autom√°tico basado en drift y nuevos datos

MLOps no es solo una colecci√≥n de herramientas, sino una cultura de colaboraci√≥n, automatizaci√≥n y mejora continua que permite a las organizaciones extraer valor real de sus inversiones en Machine Learning.

---

## 5. Referencias

### Documentaci√≥n Oficial

1. **MLflow Documentation**. (2024). *MLflow Official Documentation*. Recuperado de: https://mlflow.org/docs/latest/index.html

2. **MLflow GitHub Repository**. (2024). *MLflow Source Code and Examples*. Recuperado de: https://github.com/mlflow/mlflow

### Art√≠culos y Publicaciones

3. Kreuzberger, D., K√ºhl, N., & Hirschl, S. (2023). *Machine Learning Operations (MLOps): Overview, Definition, and Architecture*. IEEE Access, 11, 31866-31879.

4. Treveil, M., Omont, N., Stenac, C., Lefevre, K., Phan, D., Zentici, J., ... & Heidmann, L. (2020). *Introducing MLOps*. O'Reilly Media.

5. Alla, S., & Adari, S. K. (2021). *Beginning MLOps with MLFlow: Deploy Models in AWS SageMaker, Google Cloud, and Microsoft Azure*. Apress.

### Recursos en L√≠nea

6. **Google Cloud**. (2024). *MLOps: Continuous delivery and automation pipelines in machine learning*. Recuperado de: https://cloud.google.com/architecture/mlops-continuous-delivery-and-automation-pipelines-in-machine-learning

7. **Microsoft Azure**. (2024). *MLOps: Model management, deployment, lineage, and monitoring with Azure Machine Learning*. Recuperado de: https://docs.microsoft.com/en-us/azure/machine-learning/concept-model-management-and-deployment

8. **Databricks**. (2024). *The Big Book of MLOps*. Recuperado de: https://www.databricks.com/resources/ebook/the-big-book-of-mlops

### Comunidad y Blogs

9. **Neptune.ai Blog**. (2024). *MLOps Best Practices*. Recuperado de: https://neptune.ai/blog/mlops

10. **ML-Ops.org**. (2024). *MLOps Principles and Practices*. Recuperado de: https://ml-ops.org/

### Datasets

11. **IBM Sample Data Sets**. (2024). *Telco Customer Churn Dataset*. Recuperado de: https://community.ibm.com/community/user/businessanalytics/blogs/steven-macko/2019/07/11/telco-customer-churn-1113

---

## Anexos

### C√≥digo Completo de la Demo

El c√≥digo completo de la demostraci√≥n se encuentra disponible en el repositorio GitHub:

**Repositorio**: https://github.com/Alex-byteai/tema-individual-2.git


---

[üè† Home](../../../README.md) | [Siguiente ‚û°Ô∏è](../0.8.2/0.8.2.md)