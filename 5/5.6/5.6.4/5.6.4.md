> [5. T√°cticas](../../5.md) ‚Ä∫ [5.6. Listado Consolidado](../5.6.md) ‚Ä∫ [5.6.4. T√°cticas de Rendimiento](5.6.4.md)

# 5.6.4. T√°cticas de Rendimiento

## Escenario
| Atributo | ID Escenario | Fuente Est√≠mulo | Est√≠mulo | Artefacto | Entorno | Respuesta | Medida de Respuesta | Comentario |
| :---: | :---: | :---: | :---: | :---: | :---: | :---: | :---: | :---: |
| **Rendimiento** | **ESC-01** | Usuario realizando b√∫squeda | Usuario ejecuta b√∫squeda con palabra clave en base con 10k ideas | Motor de b√∫squeda del M√≥dulo de B√∫squeda de Ideas | Base de datos con 10,000 ideas indexadas | El sistema devuelve resultados ordenados por relevancia | Tiempo de respuesta p95 ‚â§ 1 seg | Garantiza experiencia fluida en b√∫squedas b√°sicas |

### T√°ctica Elegida
La t√°ctica elegida es **Introducir Concurrencia**, espec√≠ficamente mediante el uso de √≠ndices invertidos y procesamiento paralelo de consultas.

**T√≠tulo**:
- T√°ctica de Indexaci√≥n Avanzada con Elasticsearch para Optimizaci√≥n de B√∫squedas (ESC-01).

**Contexto**:
- Los usuarios de NEXUS necesitan encontrar ideas relevantes r√°pidamente mediante palabras clave (HU001). El requisito funcional **RF001** exige un tiempo de respuesta p95 ‚â§ 1s con 10k ideas. Las b√∫squedas full-text en bases de datos relacionales o b√∫squedas secuenciales son insuficientes para cumplir esta m√©trica bajo carga concurrente.

**Alternativas**:
1. **Introducir Concurrencia (√çndices Invertidos + Procesamiento Paralelo)**:
    - Utilizar Elasticsearch con √≠ndices invertidos que permiten b√∫squedas full-text en tiempo casi constante O(1) para la localizaci√≥n de t√©rminos. El motor distribuye la consulta entre m√∫ltiples shards procesados en paralelo.
    - Proporciona b√∫squedas sub-segundo incluso con millones de documentos, scoring de relevancia avanzado (BM25).
2. **Incrementar Recursos Disponibles (Escalamiento Vertical)**:
    - Aumentar CPU y RAM del servidor de base de datos para acelerar consultas secuenciales.
    - Limitado por capacidad m√°xima del hardware, no resuelve el problema algor√≠tmico de b√∫squeda full-text.

**Criterios de Elecci√≥n**:
- Cumplir con m√©trica de rendimiento p95 ‚â§ 1s bajo carga concurrente.
- Escalabilidad horizontal para crecimiento futuro.
- Calidad de resultados con scoring de relevancia.

**Decisi√≥n**:
- Se elige la t√°ctica de **Introducir Concurrencia** mediante Elasticsearch con arquitectura de sharding y r√©plicas.

**Sustento**:
- Los **√≠ndices invertidos** de Elasticsearch permiten localizar documentos que contienen t√©rminos espec√≠ficos en tiempo casi constante. El procesamiento distribuido entre shards procesa la consulta en paralelo, agregando resultados finales. Con 3 shards primarios y 2 r√©plicas, el sistema puede procesar b√∫squedas concurrentes eficientemente, garantizando el **p95 ‚â§ 1s** requerido por RF001. Esta arquitectura escala horizontalmente agregando m√°s nodos al cl√∫ster.
---
## Escenario
| Atributo | ID Escenario | Fuente Est√≠mulo | Est√≠mulo | Artefacto | Entorno | Respuesta | Medida de Respuesta | Comentario |
| :---: | :---: | :---: | :---: | :---: | :---: | :---: | :---: | :---: |
| **Rendimiento** | **ESC-02** | Usuario escribiendo en buscador | Usuario escribe consulta y activa autocompletado | Servicio de autocompletado del m√≥dulo | Interacci√≥n en tiempo real | El sistema muestra sugerencias relevantes sin duplicados | Tiempo de respuesta p95 ‚â§ 150 ms | Cr√≠tico para UX moderna y b√∫squeda predictiva |

### T√°ctica Elegida
La t√°ctica elegida es **Incrementar Recursos Disponibles**, espec√≠ficamente mediante el uso de cach√© distribuida (Redis) para consultas frecuentes.

**T√≠tulo**:
- Implementaci√≥n de Cach√© Distribuida para Autocompletado de Alta Velocidad (ESC-02).

**Contexto**:
- El autocompletado es una funcionalidad cr√≠tica para la experiencia de usuario (HU008). El requisito **RF005** exige p95 ‚â§ 150ms, lo cual es muy exigente. Consultar Elasticsearch directamente para cada pulsaci√≥n de tecla consume recursos y puede no cumplir la m√©trica bajo carga alta.

**Alternativas**:
1. **Incrementar Recursos Disponibles (Cach√© Distribuida - Redis)**:
    - Precomputar y almacenar en Redis las sugerencias m√°s frecuentes organizadas por prefijos (Trie structure). Las consultas de autocompletado golpean primero la cach√©.
    - Latencia sub-milisegundo desde Redis, reduce carga en Elasticsearch significativamente.
2. **Mantener M√∫ltiples Copias (R√©plicas de Elasticsearch)**:
    - Aumentar r√©plicas de Elasticsearch para distribuir carga de autocompletado.
    - Mayor costo de infraestructura, latencia sigue siendo mayor que cach√© en memoria.

**Criterios de Elecci√≥n**:
- Cumplir con m√©trica ultra-exigente p95 ‚â§ 150ms.
- Reducir carga en Elasticsearch para optimizar costos.
- Experiencia de usuario fluida sin lag perceptible.

**Decisi√≥n**:
- Se elige la t√°ctica de **Incrementar Recursos Disponibles** mediante cach√© distribuida Redis con estructura Trie para prefijos.

**Sustento**:
- Redis proporciona latencias de **< 1ms** para operaciones de lectura en memoria. Implementando una estructura Trie con los t√©rminos y prefijos m√°s frecuentes (actualizada cada 5 minutos), el 80% de las consultas de autocompletado se resuelven desde cach√©. Para consultas no cacheadas, se ejecuta contra Elasticsearch con n-grams precomputados. Esta arquitectura h√≠brida garantiza el **p95 ‚â§ 150ms** requerido por RF005, mejorando significativamente la UX.
---
## Escenario
| Atributo | ID Escenario | Fuente Est√≠mulo | Est√≠mulo | Artefacto | Entorno | Respuesta | Medida de Respuesta | Comentario |
| :---: | :---: | :---: | :---: | :---: | :---: | :---: | :---: | :---: |
| **Rendimiento** | **ESC-05** | M√∫ltiples usuarios simult√°neos | 500+ usuarios realizan b√∫squedas complejas concurrentemente | Servidor de b√∫squeda y base de datos | Pico de tr√°fico en horario prime | El sistema mantiene tiempos de respuesta aceptables mediante cach√© e indexaci√≥n | p95 ‚â§ 2 seg, p99 ‚â§ 3 seg | Asegura escalabilidad en momentos de alta demanda |

### T√°ctica Elegida
La t√°ctica elegida es **Mantener M√∫ltiples Copias**, espec√≠ficamente mediante replicaci√≥n activa de servicios y sharding de datos.

**T√≠tulo**:
- Implementaci√≥n de Escalamiento Horizontal con Replicaci√≥n y Sharding para Alta Concurrencia (ESC-05).

**Contexto**:
- NEXUS espera picos de tr√°fico durante eventos de marketing o lanzamientos importantes. El M√≥dulo 1 debe soportar 500+ usuarios realizando b√∫squedas complejas (m√∫ltiples filtros, ordenamiento) simult√°neamente, manteniendo p95 ‚â§ 2s y p99 ‚â§ 3s.

**Alternativas**:
1. **Mantener M√∫ltiples Copias (Replicaci√≥n + Sharding)**:
    - Desplegar m√∫ltiples instancias del microservicio de b√∫squeda con balanceador de carga (ALB). Configurar Elasticsearch con 3 shards primarios y 2 r√©plicas por shard distribuidas en 3 nodos.
    - Distribuye carga entre r√©plicas de servicio y paraleliza consultas entre shards de datos.
2. **Incrementar Recursos (Escalamiento Vertical)**:
    - Aumentar capacidad de servidor √∫nico con m√°s CPU/RAM.
    - L√≠mite f√≠sico de hardware, punto √∫nico de falla, mayor costo por unidad de capacidad.

**Criterios de Elecci√≥n**:
- Soportar 500+ usuarios concurrentes sin degradaci√≥n.
- Cumplir m√©tricas p95 ‚â§ 2s, p99 ‚â§ 3s bajo pico de carga.
- Elasticidad para crecer/decrecer seg√∫n demanda.

**Decisi√≥n**:
- Se elige la t√°ctica de **Mantener M√∫ltiples Copias** mediante auto-scaling horizontal del microservicio y arquitectura distribuida de Elasticsearch.

**Sustento**:
- Desplegando el microservicio en **Kubernetes con HPA** (Horizontal Pod Autoscaler) configurado para escalar de 2 a 10 r√©plicas basado en CPU > 70% y latencia p95, el sistema distribuye autom√°ticamente la carga. Elasticsearch con **3 shards primarios + 2 r√©plicas** distribuye consultas en paralelo entre 9 copias de datos (3√ó3). Un Application Load Balancer distribuye tr√°fico con round-robin entre r√©plicas de servicio. Esta arquitectura garantiza **p95 ‚â§ 2s** y **p99 ‚â§ 3s** durante picos de 500+ usuarios concurrentes, cumpliendo ESC-05.
---
## Escenario
| **Atributo** | **ID Escenario** | **Fuente Est√≠mulo** | **Est√≠mulo** | **Artefacto** | **Entorno** | **Respuesta** | **Medida de Respuesta** | **Comentario** |
|---------------|------------------|----------------------|---------------|----------------|--------------|----------------|--------------------------|----------------|
| **Rendimiento** | ESC-02 | M√∫ltiples usuarios concurrentes | Carga masiva al listar y filtrar ideas publicadas | Servidor del M√≥dulo de Gesti√≥n de Ideas | Evento de alta concurrencia | Respuesta mantiene tiempo aceptable mediante cach√© y r√©plicas | Tiempo de respuesta ‚â§ 2 seg con 500 usuarios concurrentes | Asegura escalabilidad y experiencia fluida |

### **T√°ctica Elegida**
La t√°ctica elegida es **Replicaci√≥n Activa y Caching** para mantener el rendimiento bajo alta concurrencia.

**T√≠tulo:**
- *Uso de Replicaci√≥n Activa y Caching para mejorar rendimiento bajo alta concurrencia (ESC-02).*

**Contexto:**
Durante lanzamientos o eventos, el m√≥dulo puede recibir miles de solicitudes simult√°neas al listar ideas, lo que exige optimizar consultas y distribuci√≥n de carga.

**Alternativas:**
- **Replicaci√≥n Activa (Escalamiento Horizontal):** Multiplicar instancias del microservicio y balancear carga.  
- **Caching de Consultas (Redis / Memory Cache):** Guardar resultados frecuentes de b√∫squedas o listados.

**Criterios de Elecci√≥n:**
- Tiempo de respuesta ‚â§ 2 seg  
- Eficiencia en picos de tr√°fico  
- Uso √≥ptimo de infraestructura  

**Decisi√≥n:**
Se combinan ambas t√°cticas: **Replicaci√≥n Activa** para escalar horizontalmente y **Caching Redis** para reducir tiempos de respuesta.

**Sustento:**
Garantiza disponibilidad ‚â• 90% y respuesta ‚â§ 2 seg en escenarios de alta concurrencia sin comprometer la integridad del sistema.

---
## Escenario
| Atributo | ID Escenario | Fuente Est√≠mulo | Est√≠mulo | Artefacto | Entorno | Respuesta | Medida de Respuesta | Comentario |
| :---: | :---: | :---: | :---: | :---: | :---: | :---: | :---: | :---: |
| **Rendimiento** | **ESC-02** | Carga masiva de usuarios | Pico masivo de tr√°fico con miles de usuarios concurrentes | Servidor principal del M√≥dulo de Publicaci√≥n de Ideas | Evento de alta concurrencia | El sistema escala horizontalmente manteniendo respuesta aceptable | Disponibilidad ‚â• 90% | Garantiza confiabilidad en momentos cr√≠ticos |

### T√°ctica Elegida
La t√°ctica elegida es **Replicaci√≥n de Componentes** (Escalamiento Horizontal), que permite distribuir la carga de las solicitudes de creaci√≥n y edici√≥n.

**T√≠tulo**:
- Uso de Replicaci√≥n Activa para Escalamiento Horizontal en el Microservicio de Ideas (ESC-02).

**Contexto**:
- NEXUS espera picos de tr√°fico ante eventos de marketing o grandes lanzamientos (ESC-02). El M√≥dulo 2 debe manejar miles de usuarios creando y editando ideas simult√°neamente. Como se defini√≥ en el ADR de Arquitectura, este es un microservicio.

**Alternativas**:
1. **Replicaci√≥n de Componentes (Activa/Pasiva)**:
    - Crear m√∫ltiples instancias id√©nticas del microservicio de Ideas y distribuir el tr√°fico entre ellas con un Balanceador de Carga. Todas las instancias activas pueden recibir peticiones.
    - Permite la **Escalabilidad Horizontal**, que es ideal para picos de tr√°fico inesperados.
2. **Asignaci√≥n de Recursos (Incremento Vertical)**:
    - Aumentar la capacidad de la √∫nica instancia del servidor (m√°s CPU, m√°s RAM).
    - Limitado por la capacidad m√°xima del servidor y requiere *downtime* para aplicar cambios.

**Criterios de Elecci√≥n**:
- Manejar picos masivos de tr√°fico sin degradaci√≥n del servicio.
- Cumplir con la medida de respuesta de **Disponibilidad ‚â• 90%** durante el pico.
- Compatibilidad con la arquitectura de microservicios.

**Decisi√≥n**:
- Se elige la t√°ctica de **Replicaci√≥n de Componentes** en modo activo, combinada con Balanceo de Carga L7 (*Application Load Balancer*).

**Sustento**:
- La **Replicaci√≥n de Componentes** (Escalamiento Horizontal) es la forma m√°s efectiva y sencilla de asegurar que el M√≥dulo de Ideas pueda absorber la carga masiva (ESC-02). El Balanceador de Carga distribuir√° las solicitudes entre las r√©plicas del servicio. Si una instancia falla, el *load balancer* la saca de la rotaci√≥n, manteniendo la disponibilidad requerida. Esto es un est√°ndar de la industria que se implementa f√°cilmente en plataformas *cloud* (como se mencion√≥ en la ADR de CDN).

---

[‚¨ÖÔ∏è Anterior](../5.6.3/5.6.3.md) | [üè† Home](../../../README.md) | [Siguiente ‚û°Ô∏è](../5.6.5/5.6.5.md)