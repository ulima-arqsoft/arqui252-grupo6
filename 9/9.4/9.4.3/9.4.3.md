> [9. Metodolog√≠a de Dise√±o de Arquitectura - Aplicaci√≥n de ADD](../../9.md) ‚Ä∫ [9.4. Iteraci√≥n 3: Refinar estructuras para abordar el atributo de calidad m√°s importante](../9.4.md) ‚Ä∫ [9.4.3. Conceptos de dise√±o](9.4.3.md)

## 9.4.3. Conceptos de dise√±o

## Conceptos de Dise√±o

Esta secci√≥n documenta las t√°cticas y patrones aplicados para optimizar el rendimiento en tiempo real del MS Colaboraci√≥n.

---

### 1. T√°ctica: Redis Pub/Sub Adapter para Socket.IO

#### Descripci√≥n

Socket.IO Redis Adapter permite que m√∫ltiples instancias del servidor compartan eventos de WebSocket mediante Redis Pub/Sub.

#### Implementaci√≥n

```typescript
import { IoAdapter } from '@nestjs/platform-socket.io';
import { createAdapter } from '@socket.io/redis-adapter';
import { createClient } from 'redis';

export class RedisIoAdapter extends IoAdapter {
  private adapterConstructor: ReturnType<typeof createAdapter>;

  async connectToRedis(): Promise<void> {
    const pubClient = createClient({ url: 'redis://localhost:6379' });
    const subClient = pubClient.duplicate();

    await Promise.all([pubClient.connect(), subClient.connect()]);

    this.adapterConstructor = createAdapter(pubClient, subClient);
  }

  createIOServer(port: number, options?: any): any {
    const server = super.createIOServer(port, options);
    server.adapter(this.adapterConstructor);
    return server;
  }
}
```

#### Beneficios

- **Escalado Horizontal**: M√∫ltiples instancias sincronizadas
- **Sticky Sessions No Requeridas**: Cualquier instancia puede manejar cualquier cliente
- **Distribuci√≥n de Carga**: Load balancer puede usar round-robin

---

### 2. T√°ctica: Cache-Aside para Mensajes Recientes

#### Descripci√≥n

Cachear los √∫ltimos N mensajes de cada sala en Redis para reducir consultas a PostgreSQL.

#### Implementaci√≥n

```typescript
@Injectable()
export class ChatService {
  async getRecentMessages(roomId: string, limit: number = 50): Promise<Message[]> {
    const cacheKey = `room:${roomId}:messages:recent`;
    
    // Intentar obtener de cach√©
    const cached = await this.redisAdapter.get(cacheKey);
    if (cached) {
      return JSON.parse(cached);
    }
    
    // Si no est√° en cach√©, consultar BD
    const messages = await this.messageRepo.findByRoom(roomId, limit);
    
    // Guardar en cach√© (TTL: 5 minutos)
    await this.redisAdapter.set(cacheKey, JSON.stringify(messages), 300);
    
    return messages;
  }
}
```

#### Beneficios

- **Reducci√≥n de Latencia**: Lectura de Redis (~1ms) vs PostgreSQL (~10-50ms)
- **Menor Carga en BD**: Menos consultas a PostgreSQL
- **Escalabilidad**: Redis puede manejar miles de lecturas/segundo

---

### 3. T√°ctica: Queue-Based Load Leveling

#### Descripci√≥n

Encolar persistencia de mensajes en RabbitMQ para suavizar picos de carga.

#### Flujo

![Diagrama de Secuencia - CU04: Registrar Idea](./diagrama/Queue-Based.png)

#### Beneficios

- **Latencia Baja**: Cliente recibe ACK sin esperar persistencia
- **Suavizado de Picos**: Cola absorbe picos de tr√°fico
- **Resiliencia**: Mensajes no se pierden si BD est√° temporalmente ca√≠da

---

### 4. T√°ctica: Connection Pooling

#### Descripci√≥n

Mantener pool de conexiones a PostgreSQL y Redis para reducir overhead de conexi√≥n.

#### Configuraci√≥n

```typescript
// TypeORM para PostgreSQL
TypeOrmModule.forRoot({
  type: 'postgres',
  host: 'localhost',
  port: 5432,
  database: 'nexus_collaboration',
  extra: {
    pool: {
      max: 20,  // M√°ximo de conexiones
      min: 5,   // M√≠nimo de conexiones
      idleTimeoutMillis: 30000
    }
  }
})

// Redis
createClient({
  socket: {
    reconnectStrategy: (retries) => Math.min(retries * 50, 500)
  },
  database: 0
})
```

---

### 5. Patr√≥n: Horizontal Pod Autoscaler (HPA)

#### Descripci√≥n

Kubernetes escala autom√°ticamente el n√∫mero de pods del MS Colaboraci√≥n seg√∫n CPU/memoria.

#### Configuraci√≥n

```yaml
apiVersion: autoscaling/v2
kind: HorizontalPodAutoscaler
metadata:
  name: collaboration-service-hpa
spec:
  scaleTargetRef:
    apiVersion: apps/v1
    kind: Deployment
    name: collaboration-service
  minReplicas: 2
  maxReplicas: 10
  metrics:
  - type: Resource
    resource:
      name: cpu
      target:
        type: Utilization
        averageUtilization: 70
  - type: Resource
    resource:
      name: memory
      target:
        type: Utilization
        averageUtilization: 80
```

---

### 6. T√°ctica: Sticky Sessions (Opcional)

Aunque Redis Adapter elimina la necesidad, se puede configurar sticky sessions en NGINX para optimizar:

```nginx
upstream collaboration_backend {
    ip_hash;  # Sticky sessions por IP
    server collab-1:3004;
    server collab-2:3004;
    server collab-3:3004;
}
```

---

### Resumen de T√°cticas Aplicadas

| T√°ctica | Prop√≥sito | Impacto en ESC-01/ESC-08 |
|---|---|---|
| **Redis Pub/Sub Adapter** | Escalado horizontal | Permite m√∫ltiples instancias ‚Üí mayor capacidad |
| **Cache-Aside** | Reducir latencia de lectura | Mensajes recientes en ~1ms vs ~20ms |
| **Queue-Based Load Leveling** | Suavizar picos | ACK inmediato, persistencia as√≠ncrona |
| **Connection Pooling** | Reducir overhead | Menos tiempo en establecer conexiones |
| **HPA** | Escalado autom√°tico | A√±ade pods cuando CPU >70% |

---

[üè† Home](../../../README.md) | [Siguiente ‚û°Ô∏è](../9.4.4/9.4.4.md)
