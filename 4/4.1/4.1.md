> [4. Decisiones Iniciales de Arquitectura](../4.md) › [4.1. Módulo 1 / Integrante 1](4.1.md)

# 4.1. Módulo 1 / Integrante 1

## Decisión 1 (Motor de Búsqueda)

**Título**:

- Elección de un Motor de Búsqueda Especializado para Indexación y Consulta de Ideas

**Contexto**:

El Módulo 1 gestiona la búsqueda y descubrimiento de ideas. Los usuarios necesitan encontrar iniciativas relevantes mediante palabras clave, filtros múltiples (categoría, tags, habilidades, estado), ordenamiento y facetado. La búsqueda debe ser extremadamente rápida (p95 ≤ 1s con 10k ideas según RF001) y soportar búsqueda full-text avanzada con relevancia. El Módulo 4 ya decidió usar MongoDB como repositorio principal de ideas.

**Alternativas**:

1. **Búsqueda Directa en MongoDB:**
    - Utilizar índices de texto de MongoDB y consultas con operadores `$text` y `$regex`.
    - Simplicidad arquitectónica (una sola base de datos), menor overhead operativo.
    - Performance limitada para búsquedas full-text complejas, scoring de relevancia básico, facetado ineficiente con múltiples filtros, dificulta cumplir métricas de p95 ≤ 1s con alta concurrencia.

2. **Motor de Búsqueda Especializado (Elasticsearch/OpenSearch):**
    - Implementar un motor de búsqueda distribuido específicamente diseñado para búsqueda full-text, con índices invertidos optimizados.
    - Búsqueda full-text avanzada con scoring de relevancia (TF-IDF, BM25), facetado y agregaciones extremadamente eficientes, escalabilidad horizontal nativa, soporte para autocompletado con n-grams.
    - Complejidad arquitectónica adicional (sincronización de datos entre MongoDB y Elasticsearch), overhead operativo de mantener dos sistemas.

3. **Servicio de Búsqueda como Servicio (Algolia, Typesense):**
    - Utilizar un servicio SaaS especializado en búsqueda.
    - Implementación rápida, excelente performance out-of-the-box, menor overhead operativo.
    - Costos recurrentes significativos a escala, menor control sobre infraestructura, dependencia de terceros.

**Criterios de Elección:**

- **Performance de Búsqueda**: Capacidad de cumplir con métricas estrictas (p95 ≤ 1s) bajo carga concurrente.
- **Calidad de Resultados**: Scoring de relevancia avanzado y búsqueda full-text robusta.
- **Escalabilidad**: Capacidad de crecer con el volumen de ideas y usuarios sin degradación.
- **Facetado Eficiente**: Soporte nativo para agregaciones y conteos por categorías (RF008).

**Decisión:**

Se elige implementar **Elasticsearch** como motor de búsqueda especializado para el Módulo 1.

**Sustento:**

- Elasticsearch proporciona el rendimiento necesario para cumplir con RF001 (p95 ≤ 1s) mediante índices invertidos optimizados y caché de consultas frecuentes.
- El scoring de relevancia avanzado (BM25) garantiza resultados de alta calidad en búsquedas por palabra clave (HU001).
- Las agregaciones nativas de Elasticsearch son ideales para implementar facetado eficiente (HU011, RF008) con mínima latencia.
- La arquitectura distribuida permite escalar horizontalmente para soportar el crecimiento futuro de NEXUS (ESC-05).
- La sincronización con MongoDB se implementará mediante Change Streams, garantizando consistencia eventual sin impacto en la escritura de ideas.

---

## Decisión 2 (Sistema de Caché)

**Título**:

- Implementación de Caché Multicapa para Optimización de Búsquedas y Autocompletado

**Contexto:**

El Módulo 1 requiere respuestas ultra-rápidas para autocompletado (p95 ≤ 150ms según RF005) y debe optimizar búsquedas frecuentes para reducir carga en Elasticsearch. Los usuarios tienden a realizar búsquedas similares (términos populares, categorías frecuentes), lo que genera oportunidades de optimización mediante caché.

**Alternativas:**

1. **Sin Caché (Consultas Directas a Elasticsearch):**
    - Todas las consultas se ejecutan directamente contra Elasticsearch.
    - Simplicidad arquitectónica, datos siempre actualizados.
    - Mayor latencia en consultas frecuentes, mayor carga en Elasticsearch, dificulta cumplir métrica de autocompletado (p95 ≤ 150ms), costos más altos de infraestructura.

2. **Caché en Memoria de Aplicación (In-Memory Cache):**
    - Implementar caché local en cada instancia del microservicio usando estructuras de datos en memoria.
    - Latencia mínima (microsegundos), sin dependencias externas.
    - Inconsistencia entre instancias en arquitectura distribuida, memoria limitada por instancia, invalidación de caché compleja.

3. **Caché Distribuida (Redis/Memcached):**
    - Implementar una capa de caché distribuida compartida entre todas las instancias del microservicio.
    - Consistencia entre instancias, latencia ultra-baja (sub-milisegundo), escalabilidad independiente, TTL configurable para balance actualización/performance.
    - Dependencia adicional en la arquitectura, complejidad en estrategias de invalidación.

**Criterios de Elección:**

- **Latencia**: Capacidad de cumplir con p95 ≤ 150ms para autocompletado.
- **Consistencia**: Garantizar experiencia uniforme entre todas las instancias del servicio.
- **Escalabilidad**: Capacidad de crecer independientemente del servicio de búsqueda.
- **Eficiencia de Recursos**: Reducir carga en Elasticsearch para optimizar costos.

**Decisión:**

Se elige implementar **Redis** como sistema de caché distribuida con estrategia multicapa.

**Sustento:**

- Redis proporciona latencias sub-milisegundo que garantizan cumplir con RF005 (p95 ≤ 150ms) para autocompletado, incluso considerando overhead de red.
- La arquitectura distribuida asegura consistencia entre todas las instancias del microservicio de búsqueda.
- Se implementarán tres niveles de caché:
  1. **Caché de Autocompletado**: Prefijos frecuentes con TTL corto (5 minutos)
  2. **Caché de Resultados**: Búsquedas frecuentes completas con TTL medio (15 minutos)
  3. **Caché de Facetas**: Conteos por categoría/tags con TTL largo (30 minutos)
- La estrategia de invalidación usará TTL + invalidación proactiva vía eventos de publicación/actualización de ideas.
- Redis reduce significativamente la carga en Elasticsearch, permitiendo escalar de manera más económica.

---

## Decisión 3 (Estrategia de Sincronización)

**Título**:

- Implementación de Sincronización Asíncrona mediante Event-Driven Architecture para Actualización del Índice de Búsqueda

**Contexto:**

El Módulo 1 necesita mantener su índice de Elasticsearch sincronizado con los datos maestros en MongoDB (Módulo 4). Cada vez que se crea, actualiza o elimina una idea, el índice de búsqueda debe reflejarlo. La sincronización debe ser confiable, escalable y no debe impactar el rendimiento del Módulo 4 (publicación de ideas).

**Alternativas:**

1. **Sincronización Síncrona (Dual-Write):**
    - El Módulo 4 escribe simultáneamente en MongoDB y llama al API del Módulo 1 para actualizar Elasticsearch.
    - Consistencia inmediata, implementación directa.
    - Acoplamiento fuerte entre módulos, mayor latencia en operaciones de escritura del Módulo 4, riesgo de inconsistencia si falla una escritura, afecta disponibilidad (si Elasticsearch cae, no se pueden publicar ideas).

2. **Sincronización Asíncrona via Polling:**
    - El Módulo 1 consulta periódicamente MongoDB buscando cambios recientes.
    - Desacoplamiento entre módulos, no impacta escritura del Módulo 4.
    - Latencia de sincronización (según intervalo de polling), ineficiente (consultas constantes aunque no haya cambios), dificulta garantizar orden de eventos.

3. **Sincronización Asíncrona via Event Streaming (MongoDB Change Streams + Message Queue):**
    - MongoDB emite eventos de cambio (Change Streams) que se publican en una cola de mensajes (RabbitMQ/Kafka), el Módulo 1 consume estos eventos y actualiza Elasticsearch.
    - Desacoplamiento total, latencia baja (milisegundos-segundos), orden garantizado de eventos, escalabilidad independiente, resiliencia (cola actúa como buffer).
    - Consistencia eventual (no inmediata), complejidad arquitectónica adicional.

**Criterios de Elección:**

- **Desacoplamiento**: Independencia entre módulos para facilitar evolución y mantenimiento.
- **Rendimiento del Módulo 4**: No impactar la latencia de publicación de ideas.
- **Confiabilidad**: Garantizar que todos los cambios se sincronicen eventualmente.
- **Latencia de Sincronización**: Balance entre inmediatez y complejidad.

**Decisión:**

Se elige **Sincronización Asíncrona via Event Streaming** utilizando MongoDB Change Streams + RabbitMQ.

**Sustento:**

- MongoDB Change Streams permite detectar cambios en tiempo real sin polling, con overhead mínimo.
- RabbitMQ actúa como buffer confiable que garantiza entrega de eventos incluso si el Módulo 1 está temporalmente caído (ESC-03).
- El desacoplamiento total permite que el Módulo 4 opere independientemente del estado de Elasticsearch, mejorando disponibilidad general.
- La latencia de sincronización (típicamente < 2 segundos) es aceptable para el caso de uso de NEXUS.
- Patrones de reintentos y dead-letter queues garantizan confiabilidad ante fallos temporales.
- La arquitectura permite escalar consumidores del Módulo 1 independientemente según la carga.

---

## Decisión 4 (Control de Acceso y Visibilidad)

**Título**:

- Implementación de Filtrado de Visibilidad a Nivel de Consulta con Caché por Usuario

**Contexto:**

El Módulo 1 debe respetar la visibilidad de las ideas (pública/privada/compartida) según RF007 y ESC-04. Cada búsqueda debe filtrar resultados según los permisos del usuario autenticado. La verificación de permisos no debe degradar significativamente el rendimiento de búsqueda (p95 ≤ 1s).

**Alternativas:**

1. **Filtrado Post-Consulta en Aplicación:**
    - Elasticsearch devuelve todos los resultados, la aplicación verifica permisos y filtra.
    - Implementación simple en lógica de aplicación.
    - Ineficiente (se traen datos que se descartarán), paginación incorrecta (página incompleta si se filtran resultados), no cumple métricas de rendimiento a escala.

2. **Filtrado a Nivel de Consulta con ACL en Índice:**
    - Cada documento en Elasticsearch incluye campos de ACL (Access Control List), las consultas incluyen filtros booleanos sobre estos campos.
    - Eficiente (Elasticsearch filtra nativamente), paginación correcta, rendimiento óptimo.
    - Índice crece con información de permisos, mayor complejidad en sincronización si cambian permisos.

3. **Servicio de Autorización Externo:**
    - Llamar a un servicio de autorización centralizado para cada resultado.
    - Centralización de lógica de permisos, auditoría completa.
    - Latencia adicional por cada llamada de red, dificulta cumplir métricas de rendimiento, mayor complejidad operacional.

**Criterios de Elección:**

- **Rendimiento**: Mantener métricas de búsqueda (p95 ≤ 1s) con filtrado de visibilidad.
- **Corrección**: Garantizar que el 100% de ideas respeten visibilidad (ESC-04).
- **Escalabilidad**: Soportar millones de ideas con diferentes niveles de visibilidad.
- **Simplicidad Operacional**: Minimizar dependencias externas en ruta crítica.

**Decisión:**

Se elige **Filtrado a Nivel de Consulta con ACL en Índice** combinado con caché de permisos de usuario.

**Sustento:**

- Elasticsearch realiza el filtrado de manera nativa y eficiente mediante filtros booleanos, sin impacto significativo en rendimiento.
- Cada documento indexado incluye campos: `visibility` (public/private/shared), `owner_id`, `shared_with[]` (lista de user_ids).
- Las consultas incluyen automáticamente cláusulas: `(visibility:public OR owner_id:{user_id} OR shared_with:{user_id})`.
- Se implementa caché Redis de permisos de usuario (grupos/organizaciones) con TTL de 5 minutos para reducir complejidad de consultas.
- La sincronización vía Change Streams actualiza ACLs en Elasticsearch cuando cambian permisos de ideas.
- Esta arquitectura garantiza 100% de corrección en visibilidad (ESC-04) manteniendo rendimiento óptimo.

---

## Decisión 5 (Observabilidad y Telemetría)

**Título**:

- Implementación de Sistema de Telemetría Distribuida para Monitoreo de Búsquedas y Optimización Basada en Datos

**Contexto:**

El Módulo 1 requiere telemetría completa según RF009 y ESC-10 para monitorear rendimiento, detectar problemas temprano y optimizar la experiencia de búsqueda mediante análisis de patrones de uso. Los datos de telemetría deben capturarse sin impactar la latencia de búsqueda.

**Alternativas:**

1. **Logging Básico en Archivos:**
    - Escribir eventos de búsqueda en archivos de log locales.
    - Simplicidad, bajo overhead inicial.
    - Dificulta análisis agregado, sin métricas en tiempo real, problemas de almacenamiento a escala, no permite alertas proactivas.

2. **Sistema de Métricas (Prometheus) + Logging Estructurado (ELK Stack):**
    - Métricas de rendimiento en Prometheus, eventos detallados en Elasticsearch via Logstash/Fluentd.
    - Separación de concerns (métricas vs logs), excelente para análisis y alertas, ecosistema maduro.
    - Complejidad operacional de múltiples sistemas, posible duplicación de almacenamiento.

3. **Plataforma de Observabilidad Unificada (Datadog, New Relic, Elastic APM):**
    - Solución todo-en-uno para métricas, logs y traces distribuidos.
    - Implementación rápida, correlación automática, menor overhead operacional.
    - Costos recurrentes significativos a escala, dependencia de terceros, menor control sobre datos.

**Criterios de Elección:**

- **Visibilidad Completa**: Capturar 100% de eventos de búsqueda según RF009.
- **Performance**: Overhead mínimo en latencia de búsqueda (< 5ms).
- **Análisis en Tiempo Real**: Métricas y alertas inmediatas ante degradación.
- **Cost-Effectiveness**: Balance entre capacidad y costo operacional.

**Decisión:**

Se elige implementar **Sistema de Métricas (Prometheus) + Logging Estructurado (ELK Stack)** con sampling inteligente.

**Sustento:**

- **Prometheus** captura métricas de rendimiento en tiempo real (latencias p50/p95/p99, throughput, tasa de errores) con overhead mínimo.
- **Elasticsearch (vía Filebeat/Logstash)** almacena eventos detallados de búsqueda (`search_performed`, `result_click`) para análisis histórico.
- Se implementa **sampling inteligente**: 
  - 100% de búsquedas generan métricas (Prometheus)
  - 100% de búsquedas lentas (> 1s) se loggean detalladamente
  - 10% de búsquedas normales se loggean para análisis de patrones
- **Grafana** proporciona dashboards en tiempo real y alertas configurables.
- El sistema captura: términos de búsqueda (anonimizados), filtros aplicados, tiempo de respuesta, resultados devueltos, clicks en resultados.
- Esta arquitectura permite optimización basada en datos (identificar búsquedas lentas, términos populares para precomputar, etc.) cumpliendo ESC-10.

---

[🏠 Home](../../README.md) | [Siguiente ➡️](../4.2/4.2.md)